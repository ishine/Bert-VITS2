# Changelog

## v1.3 (2024-01-09)

### 大きい変更
- 元々のBert-VITS2に存在した、日本語の発音・アクセント処理部分のバグを修正・リファクタリング
    - `車両`が`シャリヨオ`、`思う`が`オモオ`、`見つける`が`ミッケル`等に発音・学習されており、その単語以降のアクセント情報が全て死んでいた
    - `私はそれを見る`のアクセントが`ワ➚タシ➘ワ　ソ➚レ➘オ　ミ➘ル`だったのを`ワ➚タシワ　ソ➚レオ　ミ➘ル`に修正
    - 学習・音声合成で無視されていたアルファベット・ギリシャ文字を無視しないように変更（基本はアルファベット読みだけど簡単な単語は読めるらしい、学習の際は念のためカタカナ等にしたほうがよいです）
    - 修正の影響で、前処理時に（今まで無視されていた）読めない漢字等で引っかかるようになりました。その場合は書き起こしを確認して修正するようにしてください。
- アクセントを調整して音声合成できるように（完全に制御できるわけではないが改善される場合がある）。

これまでのモデルもこれまで通り使え、アクセントや発音等が改善される可能性があります。新しいバージョンで学習し直すとより良くなる可能性もあります。が劇的に良くなるかは分かりません。

### 改善
- `Dataset.bat`の音声スライスと書き起こしをよりカスタマイズできるように（スライスの秒数設定や書き起こしのWhisperモデル指定や言語指定等）
- `Style.bat`のスタイル分けで、スタイルごとのサンプル音声を指定した数だけ複数再生できるように。また新しい次元削減方法（UMAP）と新しいスタイル分けの方法（DBSCAN）を追加（UMAPのほうがよくスタイルが分かれるかもしれません）
- `App.bat`での音声合成時に複数話者モデルの場合に話者を指定できるように
- colabの[ノートブック](http://colab.research.google.com/github/litagin02/Style-Bert-VITS2/blob/master/colab.ipynb)で、音声ファイルのみからデータセットを作成するオプション部分を追加
- クラウド実行等の際にパスの指定をこちらでできるように、パスの設定を`configs/paths.yml`にまとめた（colabの[ノートブック](http://colab.research.google.com/github/litagin02/Style-Bert-VITS2/blob/master/colab.ipynb)もそれに伴って更新）。デフォルトは`dataset_root: Data`と`assets_root: model_assets`なので、クラウド等でやる方はここを変更してください。
- どのステップ数の出力がよいかの「一つの」指標として [SpeechMOS](https://github.com/tarepan/SpeechMOS) を使うスクリプトを追加：
```bash
python speech_mos.py -m <model_name>
```
ステップごとの自然性評価が表示され、`mos_results`フォルダの`mos_{model_name}.csv`と`mos_{model_name}.png`に結果が保存される。読み上げさせたい文章を変えたかったら中のファイルを弄って各自調整してください。あくまでアクセントや感情表現や抑揚を全く考えない基準での評価で、目安のひとつなので、実際に読み上げさせて選別するのが一番だと思います。
- 学習時のウォームアップオプションを機能するように（ [@kale4eat](https://github.com/kale4eat) 様によるPRです、ありがとうございます！）。前処理時に生成される`config.json`の`train`の`warmup_epochs`を変更することで、ウォームアップのエポック数を変更できます。デフォルトは`0`で今までと同じ学習率の挙動です。

### その他
- `Dataset.bat`の音声スライスでノーマライズ機能を削除（学習前処理で行えるため）
- `Train.bat`の音量ノーマライズと無音切り詰めをデフォルトでオフに変更
- 学習時の進捗を全体エポック数で表示し、学習全体の進捗を見やすいように( [@RedRayz](https://github.com/RedRayz) 様によるPRです、ありがとうございます！)
- その他バグ修正等（ [@tinjyuu](https://github.com/@tinjyuu) 様、 [@darai0512](https://github.com/darai0512) 様ありがとうございます！）
- `config.json`にスタイル埋め込み部分を学習しない`freeze_style`オプションを追加（デフォルトは`false`）

### TIPS
- 日本語学習の場合、`config.json`の`freeze_bert`と`freeze_en_bert`を`true`にしておくと、英語と中国語の発話能力が学習の過程で落ちないかもしれませんが、あまり比較していなので分かりません。

## v1.2 (2023-12-31)

- グラボがないユーザーでの音声合成をサポート、`Install-Style-Bert-VITS2-CPU.bat`でインストール。
- Google Colabでの学習をサポート、[ノートブック](http://colab.research.google.com/github/litagin02/Style-Bert-VITS2/blob/master/colab.ipynb)を追加
- 音声合成のAPIサーバーを追加、`python server_fastapi.py`で起動します。API仕様は起動後に`/docs`にて確認ください。（ [@darai0512](https://github.com/darai0512) 様によるPRです、ありがとうございます！）
- 学習時に自動的にデフォルトスタイル Neutral を生成するように。特にスタイル指定が必要のない方は、学習したらそのまま音声合成を試せます。これまで通りスタイルを自分で作ることもできます。
- マージ機能の新規追加: `Merge.bat`, `webui_merge.py`
- 前処理のリサンプリング時に音声ファイルの開始・終了部分の無音を削除するオプションを追加（デフォルトでオン）
- `スタイルテキスト (style text)`がスタイル指定と紛らわしかったので、`アシストテキスト (assist text)`に変更
- その他コードのリファクタリング

## v1.1 (2023-12-29)
- TrainとDatasetのWebUIの改良・調整（一括事前処理ボタン等）
- 前処理のリサンプリング時に音量を正規化するオプションを追加（デフォルトでオン）

## v1.0 (2023-12-27)
- 初版
